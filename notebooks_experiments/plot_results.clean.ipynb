{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4adae1-a5e2-4020-85c2-1847538d31a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import json\n",
    "import copy\n",
    "import logging\n",
    "from IPython.display import Markdown, display\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "from util.distance import dist3\n",
    "from util.scenario import Scenario\n",
    "\n",
    "box_color = '#86afb8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49ca89-67b8-4d29-868f-a5620f9cf0d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def min_distance(ndrones):\n",
    "    \"\"\"\n",
    "    Returns the minimum travel distance for each UAV from the Villalvernia scenario\n",
    "    \"\"\"\n",
    "    flightseqs_fpath = f\"../out/flight_sequences/villalvernia_{ndrones}/flight_sequences.pkl\"\n",
    "    with open(flightseqs_fpath, 'rb') as f:\n",
    "        flightseqs = pickle.load(f)   \n",
    "    sc = Scenario([], positions_w=flightseqs)\n",
    "    \n",
    "    res = {}\n",
    "    for d in range(sc.N_d):\n",
    "        res[d] = sc.D_N[d].sum()\n",
    "    return res\n",
    "\n",
    "def sum_distance_from_dir(eventsdir):\n",
    "    \"\"\"\n",
    "    Returns the collective distance from the events directory for all UAVs\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for d, fname in enumerate(os.listdir(eventsdir)):\n",
    "        fpath = os.path.join(eventsdir, fname)\n",
    "        df = pd.read_csv(fpath)\n",
    "        res[d] = sum_distance_from_df(df)\n",
    "    return res\n",
    "\n",
    "def sum_distance_from_df(df):\n",
    "    \"\"\"\n",
    "    Returns the collective distance between all nodes visited in the event dataframe\n",
    "    \"\"\"\n",
    "    res = 0\n",
    "    for i in range(df.shape[0]-1):\n",
    "        a = df.iloc[i][['node_x', 'node_y', 'node_z']]\n",
    "        b = df.iloc[i+1][['node_x', 'node_y', 'node_z']]\n",
    "        dist = dist3(a,b)\n",
    "        res += dist\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a05f3c-9756-4f66-8fa7-e78e05e82b0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_nr_charge_cycles(loaded):\n",
    "    nr_drones = loaded['scenario']['nr_drones']\n",
    "\n",
    "    res = []\n",
    "    for d in range(nr_drones):\n",
    "        charge_cycles = 0\n",
    "        currently_charging = False\n",
    "        for ev in loaded['events'][d]:\n",
    "            if ev['type'] == 'charged':\n",
    "                currently_charging = True            \n",
    "            elif currently_charging: \n",
    "                # stop charging            \n",
    "                charge_cycles += 1\n",
    "                currently_charging = False\n",
    "        res.append(charge_cycles)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc15b72-b2a5-42ef-b8d5-5a340f6a24a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_from_json(basedir):\n",
    "    data = []\n",
    "    for subdir in os.listdir(basedir):\n",
    "        if os.path.isdir(os.path.join(basedir, subdir)):\n",
    "            result_fpath = os.path.join(basedir, subdir, \"result.json\")\n",
    "            if not os.path.exists(result_fpath):\n",
    "                logger.info(f\"skipping '{subdir}' due to missing 'result.json' file\")\n",
    "                continue                \n",
    "            \n",
    "            with open(result_fpath, 'r') as f:\n",
    "                try:\n",
    "                    loaded = json.load(f)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"failed to load JSON for '{subdir}': {e}\")\n",
    "                    continue\n",
    "                \n",
    "                datapoint = {}\n",
    "\n",
    "                # parse parameters\n",
    "                params = loaded['params']\n",
    "                \n",
    "                cols = ['v', 'r_charge', 'r_deplete', 'B_max', 'B_min', 'epsilon', 'schedule_delta', 'W', 'sigma', 'time_limit', 'int_feas_tol', 'rescheduling_frequency']\n",
    "                for col in cols:\n",
    "                    val = params[col]\n",
    "                    if type(val) == list:\n",
    "                        val = val[0]\n",
    "                    datapoint[col] = val              \n",
    "                    \n",
    "                # parse relevant results\n",
    "                datapoint['scheduler'] = loaded['scheduler']\n",
    "                datapoint['dirname'] = subdir\n",
    "                datapoint['execution_time'] = loaded['execution_time']\n",
    "                datapoint['nr_drones'] = loaded['scenario']['nr_drones']\n",
    "                datapoint['solve_times'] = [x['t_solve'] for x in loaded['solve_times']]\n",
    "                datapoint['solve_timestamps'] = [x['timestamp'] for x in loaded['solve_times']]\n",
    "                datapoint['solve_optimality'] = [x['optimal'] for x in loaded['solve_times']]\n",
    "                datapoint['moving_times'] = [x['moving'] for x in loaded['time_spent'].values()]\n",
    "                datapoint['waiting_times'] = [x['waiting'] for x in loaded['time_spent'].values()]\n",
    "                datapoint['charging_times'] = [x['charging'] for x in loaded['time_spent'].values()]\n",
    "                datapoint['moving_times_minimum'] = [x['moving_minimum'] for x in loaded['time_spent'].values()]\n",
    "                datapoint['total_occupancy'] = [sum(x['t_end'] - x['t_start'] for x in l) for l in loaded['occupancy'].values()]\n",
    "                datapoint['nr_charge_cycles'] = get_nr_charge_cycles(loaded)\n",
    "                \n",
    "                data.append(datapoint)\n",
    "    res = pd.DataFrame(data)\n",
    "    \n",
    "    # preprocessing\n",
    "    # basic statistical functions\n",
    "    cols = ['moving_times', 'waiting_times', 'charging_times', 'solve_times', 'nr_charge_cycles']\n",
    "    for col in cols:\n",
    "        new_col = f\"{col}_cum\"\n",
    "        res[new_col] = res[col].apply(sum)\n",
    "        \n",
    "        new_col = f\"{col}_mean\"\n",
    "        res[new_col] = res[col].apply(np.mean)\n",
    "        \n",
    "        new_col = f\"{col}_min\"\n",
    "        res[new_col] = res[col].apply(np.min)\n",
    "        \n",
    "        new_col = f\"{col}_max\"\n",
    "        res[new_col] = res[col].apply(np.max)\n",
    "\n",
    "    # counts\n",
    "    cols = ['solve_times']\n",
    "    for col in cols:\n",
    "        new_col = f\"{col}_count\"\n",
    "        res[new_col] = res[col].apply(len)\n",
    "        \n",
    "    # percent spent on different actions\n",
    "    cols = ['moving_times', 'waiting_times', 'charging_times']\n",
    "    total = res[cols].apply(lambda x: sum([np.array(v) for v in x]), axis=1)\n",
    "    for col in cols:\n",
    "        new_col = f\"{col}_perc\"\n",
    "        res[new_col] = res[col].apply(np.array) / total * 100\n",
    "        \n",
    "        new_mean_col = f\"{col}_perc_mean\"\n",
    "        res[new_mean_col] = res[new_col].apply(np.mean)\n",
    "        \n",
    "    res['perc_occupancy'] = res.apply(lambda x: np.array(x['total_occupancy']) / x['execution_time'] * 100, axis=1)    \n",
    "    res['solve_optimality_perc'] = res.solve_optimality.apply(lambda x: np.sum(x) / len(x) * 100)\n",
    "    \n",
    "    # strings\n",
    "    res['scheduler'] = res.scheduler.apply(lambda x: x[:-9])\n",
    "    \n",
    "    # column renaming\n",
    "    res = res.rename(columns={'rescheduling_frequency': 'pi'})\n",
    "    \n",
    "    res['h'] = (res.W - 1) * res.sigma\n",
    "    res['perc_max_horizon_executed'] = res['pi'] / res['h'] * 100\n",
    "    res['solve_times_optimal_mean'] = res.solve_times.apply(lambda x: np.mean([e for e in x if e < 10]))\n",
    "    \n",
    "    # TOOD: extract nr charging cycles\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a74b65-22e9-4766-a505-82df7ceb1ad1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Planning horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f837-9cd0-486f-9e76-148d2e956cb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = \"../out/villalvernia/grid_search\"\n",
    "df_planning_horizon = load_data_from_json(basedir)\n",
    "# df_planning_horizon = df_planning_horizon[lambda x: x.h <= 160]\n",
    "df_planning_horizon_milp = df_planning_horizon[lambda x: x.scheduler == 'milp']\n",
    "df_planning_horizon_naive = df_planning_horizon[lambda x: x.scheduler == 'naive']\n",
    "naive_execution_time = df_planning_horizon_naive.iloc[0].execution_time\n",
    "df_planning_horizon_milp['perc_execution_time_naive'] = df_planning_horizon_milp.execution_time / naive_execution_time * 100\n",
    "\n",
    "logger.info(f\"Number of data points: {df_planning_horizon.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d304d-5f85-4223-a654-5c1bda2e125f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Ws = sorted(df_planning_horizon_milp.W.unique())\n",
    "baseline_execution_time = df_planning_horizon_naive.iloc[0].execution_time\n",
    "max_execution_time = df_planning_horizon_milp.execution_time.max()\n",
    "max_time_limit = df_planning_horizon_milp.time_limit.max()\n",
    "min_perc_execution_time_naive = df_planning_horizon_milp.perc_execution_time_naive.min()\n",
    "max_perc_execution_time_naive = df_planning_horizon_milp.perc_execution_time_naive.max()\n",
    "min_solve_times_count = df_planning_horizon_milp.solve_times_count.min()\n",
    "max_solve_times_count = df_planning_horizon_milp.solve_times_count.max()\n",
    "min_solve_times_cum = df_planning_horizon_milp.solve_times_cum.min()\n",
    "max_solve_times_cum = df_planning_horizon_milp.solve_times_cum.max()\n",
    "\n",
    "min_moving_times_mean = df_planning_horizon_milp.moving_times_mean.min()\n",
    "max_moving_times_mean = df_planning_horizon_milp.moving_times_mean.max()\n",
    "min_waiting_times_mean = df_planning_horizon_milp.waiting_times_mean.min()\n",
    "max_waiting_times_mean = df_planning_horizon_milp.waiting_times_mean.max()\n",
    "min_charging_times_mean = df_planning_horizon_milp.charging_times_mean.min()\n",
    "max_charging_times_mean = df_planning_horizon_milp.charging_times_mean.max()\n",
    "\n",
    "min_moving_times_perc_mean = df_planning_horizon_milp.moving_times_perc_mean.min()\n",
    "max_moving_times_perc_mean = df_planning_horizon_milp.moving_times_perc_mean.max()\n",
    "min_waiting_times_perc_mean = df_planning_horizon_milp.waiting_times_perc_mean.min()\n",
    "max_waiting_times_perc_mean = df_planning_horizon_milp.waiting_times_perc_mean.max()\n",
    "min_charging_times_perc_mean = df_planning_horizon_milp.charging_times_perc_mean.min()\n",
    "max_charging_times_perc_mean = df_planning_horizon_milp.charging_times_perc_mean.max()\n",
    "\n",
    "nr_cols = 17\n",
    "_, axes = plt.subplots(len(Ws), nr_cols, dpi=100, figsize=(6*nr_cols, 5*len(Ws)))\n",
    "\n",
    "for i, W in enumerate(Ws):    \n",
    "    # plot execution time\n",
    "    axidx = 0\n",
    "    rectangles = []\n",
    "    \n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_et = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'execution_time')\n",
    "    sns.heatmap(df_plot_et / 60, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\",.0f\", cbar=False, linewidths=3, vmin=0, vmax=max_execution_time / 60, ax=ax) \n",
    "    for r in range(df_plot_et.shape[0]):\n",
    "        for c in range(df_plot_et.shape[1]):\n",
    "            if df_plot_et.iloc[r,c] < baseline_execution_time:\n",
    "                # draw green rectangle around box\n",
    "                rectangles.append(patches.Rectangle((c+0.025, r+0.025), 0.95, 0.95, linestyle=\"-\", linewidth=2, edgecolor='g', facecolor='none', alpha=0.25))\n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Execution time (m) (W={W})\")\n",
    "    axidx += 1\n",
    "    \n",
    "    # plot relative execution time compared to Naive\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_pet = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'perc_execution_time_naive')\n",
    "    sns.heatmap(df_plot_pet, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".0f\", cbar=False, linewidths=3, vmin=min_perc_execution_time_naive, vmax=max_perc_execution_time_naive, ax=ax)\n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Relative execution time (%) (W={W})\")\n",
    "    axidx += 1\n",
    "    \n",
    "    # plot mean solve times\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_mst = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'solve_times_mean')\n",
    "    sns.heatmap(df_plot_mst, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=0, vmax=max_time_limit, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Mean solve time (s) (W={W})\")\n",
    "    axidx += 1\n",
    "    \n",
    "    # plot mean optimal solve times\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_mst = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'solve_times_optimal_mean')\n",
    "    sns.heatmap(df_plot_mst, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=0, vmax=max_time_limit, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Mean optimal solve time (s) (W={W})\")\n",
    "    axidx += 1\n",
    "           \n",
    "    # plot solve_time_count\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_stc = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'solve_times_count')\n",
    "    sns.heatmap(df_plot_stc, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".0f\", cbar=False, linewidths=3, vmin=min_solve_times_count, vmax=max_solve_times_count, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Solve time count (W={W})\")\n",
    "    axidx += 1\n",
    "    \n",
    "    # plot sum solve times\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_cst = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'solve_times_cum')\n",
    "    sns.heatmap(df_plot_cst, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".0f\", cbar=False, linewidths=3, vmin=min_solve_times_cum, vmax=max_solve_times_cum, ax=ax)\n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Sum solve time (s) (W={W})\")\n",
    "    axidx += 1\n",
    "    \n",
    "    # plot percentage of solves optimal\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_pst = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'solve_optimality_perc')\n",
    "    sns.heatmap(df_plot_pst, robust=True, square=True, cmap='Blues_r', annot=True, annot_kws={\"fontsize\":8}, fmt=\".0f\", cbar=False, linewidths=3, vmin=0, vmax=100, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Optimal solves (%) (W={W})\")\n",
    "    axidx += 1\n",
    "    \n",
    "    # perc occupancy (station 1)\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_po1 = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'perc_occupancy').apply(lambda x: [v[0] if type(v) == np.ndarray else v for v in x]) \n",
    "    sns.heatmap(df_plot_po1, robust=True, square=True, cmap='Blues_r', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=0, vmax=100, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"CS [1] occupancy (%) (W={W})\")\n",
    "    axidx += 1    \n",
    "    \n",
    "    # perc occupancy (station 2)\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_po1 = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'perc_occupancy').apply(lambda x: [v[1] if type(v) == np.ndarray else v for v in x]) \n",
    "    sns.heatmap(df_plot_po1, robust=True, square=True, cmap='Blues_r', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=0, vmax=100, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"CS [2] occupancy (%) (W={W})\")\n",
    "    axidx += 1\n",
    "    \n",
    "    # moving time mean\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_mwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'moving_times_mean')\n",
    "    sns.heatmap(df_plot_mwt / 60, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=min_moving_times_mean / 60, vmax=max_moving_times_mean / 60, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Mean moving time (m) (W={W})\")\n",
    "    axidx += 1 \n",
    "    \n",
    "    # waiting time mean\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_wwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'waiting_times_mean')\n",
    "    sns.heatmap(df_plot_wwt / 60, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=min_waiting_times_mean / 60, vmax=max_waiting_times_mean / 60, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Mean waiting time (m) (W={W})\")\n",
    "    axidx += 1 \n",
    "    \n",
    "    # charging time mean\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_cwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'charging_times_mean')\n",
    "    sns.heatmap(df_plot_cwt / 60, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=min_charging_times_mean / 60, vmax=max_charging_times_mean / 60, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Mean charging time (m) (W={W})\")\n",
    "    axidx += 1 \n",
    "\n",
    "    # moving time percentage mean\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_pwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'moving_times_perc_mean')\n",
    "    sns.heatmap(df_plot_pwt, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=min_moving_times_perc_mean, vmax=max_moving_times_perc_mean, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"$\\mu$ % time spent moving (W={W})\")\n",
    "    axidx += 1 \n",
    "    \n",
    "    # waiting time percentage mean\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_pwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'waiting_times_perc_mean')\n",
    "    sns.heatmap(df_plot_pwt, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=min_waiting_times_perc_mean, vmax=max_waiting_times_perc_mean, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"$\\mu$ % time spent waiting (W={W})\")\n",
    "    axidx += 1 \n",
    "    \n",
    "    # charging time percentage mean\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_pwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'charging_times_perc_mean')\n",
    "    sns.heatmap(df_plot_pwt, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=min_charging_times_perc_mean, vmax=max_charging_times_perc_mean, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"$\\mu$ % time spent charging (W={W})\")\n",
    "    axidx += 1 \n",
    "    \n",
    "    # percentage of scheduling horizon at maximum executed\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_pwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'perc_max_horizon_executed')\n",
    "    sns.heatmap(df_plot_pwt, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=0, vmax=100, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Maximum % of horizon executed (W={W})\")\n",
    "    axidx += 1 \n",
    "    \n",
    "    # percentage of scheduling horizon at maximum executed\n",
    "    ax = axes[i][axidx]\n",
    "    df_plot_pwt = df_planning_horizon_milp[lambda x: x.W == W].pivot('sigma', 'pi', 'h')\n",
    "    sns.heatmap(df_plot_pwt, robust=True, square=True, cmap='Blues', annot=True, annot_kws={\"fontsize\":8}, fmt=\".1f\", cbar=False, linewidths=3, vmin=0, vmax=100, ax=ax) \n",
    "    for rect in rectangles:\n",
    "        cpy = copy.copy(rect)\n",
    "        ax.add_patch(cpy)\n",
    "    ax.set_xlabel(\"$\\pi$\")\n",
    "    ax.set_ylabel(\"$\\sigma$\")\n",
    "    ax.set_title(f\"Scheduling horizon (W={W})\")\n",
    "    axidx += 1 \n",
    "\n",
    "plt.savefig(\"../out/figures/heatmaps.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4c996-c3fb-461d-86cc-e4faa6fa06dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*1, dpi=100)\n",
    "\n",
    "df_filtered = df_increase_sigma_milp.drop_duplicates(['sigma'])\n",
    "X = df_filtered.sigma\n",
    "Y = df_filtered.execution_time\n",
    "baseline_execution_time = df_increase_sigma[lambda x: x.schedule_type == 'naive'].iloc[0].execution_time\n",
    "\n",
    "plt.bar(X, Y, linewidth=.8, edgecolor='black', color=box_color, width=0.7)\n",
    "xmin = 0.1\n",
    "xmax = 20.8\n",
    "ax.set_xlim([xmin, xmax])\n",
    "plt.axhline(baseline_execution_time, color='red')\n",
    "plt.text(xmax-0.1, baseline_execution_time+100, \"Naive strategy\", c='red', ha='right', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_axisbelow(False)\n",
    "plt.grid(axis='y')\n",
    "plt.xticks(X, fontsize=8)\n",
    "plt.xlabel(\"$\\sigma$\")\n",
    "plt.ylabel(\"Execution time (s)\")\n",
    "\n",
    "plt.savefig(\"../out/figures/1_planning_horizon_increase_sigma.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076b490-e8dd-4147-81ce-e2da82deff09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate precise gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45465ba5-5d66-4252-86f6-638f0bab4f8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_increase_sigma[lambda x: x.sigma > 7].execution_time.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9aed7-17ea-4eaf-9e82-82601ac75905",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lowest_execution_time = df_increase_sigma[lambda x: x.sigma > 7].execution_time.min()\n",
    "print(f\"Lowest execution time = {lowest_execution_time:.1f}s\")\n",
    "print(f\"                   or = {(1 - (lowest_execution_time / baseline_execution_time)) * 100:.1f}% faster than naive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83614585-cf85-43c0-a0e9-05d40826e24e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "highest_execution_time = df_increase_sigma[lambda x: x.sigma > 7].execution_time.max()\n",
    "print(f\"Highest execution time = {highest_execution_time:.1f}s\")\n",
    "print(f\"                    or = {(1 - (highest_execution_time / baseline_execution_time)) * 100:.1f}% faster than naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8a9d7-c91f-49cd-bf3b-8a27a753d421",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Increase $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c7ee6-e2ab-4b57-8ece-ab909171be71",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = \"../out/villalvernia/1_planning_horizon/increase_W\"\n",
    "df_full_coverage = load_data(basedir)\n",
    "df_full_coverage_milp = df_full_coverage[lambda x: x.schedule_type == 'milp']\n",
    "df_full_coverage_milp = df_full_coverage_milp[lambda x: x.W > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f7c72-1d2a-4909-b13b-a6ed6f44ec0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9e353-f3b3-4cdf-821e-255502fd35bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df_full_coverage_milp.W\n",
    "Y = df_full_coverage_milp.execution_time\n",
    "baseline_execution_time = df_full_coverage[lambda x: x.schedule_type == 'naive'].iloc[0].execution_time\n",
    "\n",
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*1, dpi=100)\n",
    "plt.bar(X, Y, linewidth=.8, edgecolor='black', color=box_color, width=0.7)\n",
    "\n",
    "xmin = 6.1\n",
    "xmax = 20.8\n",
    "ax.set_xlim([xmin, xmax])\n",
    "plt.axhline(baseline_execution_time, color='red')\n",
    "plt.text(xmax-0.1, baseline_execution_time-50, \"Naive strategy\", c='red', ha='right', va='top', fontsize=9)\n",
    "\n",
    "plt.grid(axis='y')\n",
    "ax.set_xticks(X)\n",
    "ax.set_xlabel(\"W\")\n",
    "ax.set_ylabel(\"Execution time (s)\")\n",
    "\n",
    "plt.savefig(\"../out/figures/1_planning_horizon_increase_W_execution_time.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e639d7d-1ee9-4e9f-9b8e-77d552b4def6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lowest_execution_time = df_full_coverage_milp.execution_time.min()\n",
    "print(f\"Lowest execution time = {lowest_execution_time:.1f}s\")\n",
    "print(f\"                   or = {(1 - (lowest_execution_time / baseline_execution_time)) * 100:.1f}% faster than naive\")\n",
    "\n",
    "highest_execution_time = df_full_coverage_milp.execution_time.max()\n",
    "print(f\"Highest execution time = {highest_execution_time:.1f}s\")\n",
    "print(f\"                    or = {(1 - (highest_execution_time / baseline_execution_time)) * 100:.1f}% faster than naive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f6dd8-5526-4a9f-a06f-02dd8b1d817b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Solve times (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3a069-576c-40f6-add7-753e066831fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = sorted(df_full_coverage_milp.W.unique())\n",
    "Y = df_full_coverage_milp.groupby('W').solve_time.sum()\n",
    "\n",
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*1, dpi=100)\n",
    "plt.bar(X, Y, linewidth=.8, edgecolor='black', color=box_color, width=0.7)\n",
    "\n",
    "plt.grid(axis='y')\n",
    "xmin = 6.1\n",
    "xmax = 20.8\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.set_xticks(X)\n",
    "ax.set_xlabel(\"W\")\n",
    "ax.set_ylabel(\"Total solve time (s)\")\n",
    "\n",
    "plt.savefig(\"../out/figures/1_planning_horizon_increase_W_solve_time_total.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690b910-b45b-4433-8e30-9d5988f138af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Solve times (boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e866fb8-c538-46b1-8715-0c50ab373656",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*1, dpi=100)\n",
    "sns.boxplot(x=\"W\", y=\"solve_time\", data=df_full_coverage_milp, ax=ax, width=0.6, linewidth=1, whis=[0, 100], zorder=10, color=box_color)\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Solve time [log]\")\n",
    "plt.xlabel(\"$\\hat{N}_w$\")\n",
    "\n",
    "ticks = [1, 10, 60, 600]\n",
    "labels = ['1s', '10s', '1m', '10m']\n",
    "plt.yticks(ticks, labels)\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# add red horizontal line\n",
    "ax.axhline(y=600, c='red')\n",
    "offsetx, offsety = 0.1, -100\n",
    "ax.text(ax.get_xlim()[0]+offsetx, 600+offsety, 'Time limit', color='red', va='top', ha='left', fontsize=9)\n",
    "\n",
    "plt.savefig(\"../out/figures/1_planning_horizon_increase_W_solve_time_box.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641772d-f487-40e2-ba74-b4367a1ac1b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Number of drones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54379722-1178-452b-b03f-9ac2463a5dd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = \"../out/villalvernia/2_n_drones\"\n",
    "df_n_drones = load_data(basedir).drop_duplicates(['schedule_type', 'n_drones']).sort_values('schedule_type', ascending=True).sort_values('n_drones', ascending=False)\n",
    "# df_n_drones = load_data(basedir)\n",
    "df_n_drones_milp = df_n_drones[lambda x: (x.schedule_type == 'milp')]\n",
    "df_n_drones_naive = df_n_drones[lambda x: x.schedule_type == 'naive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24773346-6a79-4592-b210-2f9519b6086c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*1, dpi=100)\n",
    "df_plot = pd.concat([df_n_drones_milp, df_n_drones_naive])\n",
    "sns.barplot(x='n_drones', y='execution_time', hue='schedule_type', data=df_plot, edgecolor='black', linewidth=0.75, hue_order=['naive', 'milp'])\n",
    "\n",
    "# add gains\n",
    "for i, n_drones in enumerate(sorted(df_plot.n_drones.unique())):\n",
    "    milp_time = df_n_drones_milp[lambda x: x.n_drones == n_drones].iloc[0].execution_time\n",
    "    naive_time = df_n_drones_naive[lambda x: x.n_drones == n_drones].iloc[0].execution_time\n",
    "    max_time = max(milp_time, naive_time)\n",
    "    rel_perc = (milp_time / naive_time * 100)\n",
    "    diff = 100 - rel_perc\n",
    "\n",
    "    if diff > 0:\n",
    "        color = 'green'\n",
    "        txt = r\"$\\downarrow$\" + f\"{-diff:.1f}%\"\n",
    "    else:\n",
    "        color = 'red'\n",
    "        txt = r\"$\\uparrow$\" + f\"+{-diff:.1f}%\"\n",
    "    plt.text(i, max_time + 50, txt, ha='center', va='bottom', backgroundcolor='white', color=color, fontsize=9, bbox=dict(boxstyle='square,pad=0.1', fc='white', ec='none'))\n",
    "    \n",
    "ymin, ymax = plt.ylim()\n",
    "plt.ylim([ymin, ymax+500])\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlabel(\"$N_d$\")\n",
    "plt.ylabel(\"Execution time (s)\")\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.savefig(\"../out/figures/2_n_drones.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3aca8-075c-42b4-bc4f-47d54db17050",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Time limit on MILP solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa651f3-a7fb-433d-ad89-5d8c4a40a83d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = \"../out/villalvernia/3_solve_time\"\n",
    "df_solve_time = load_data(basedir)\n",
    "df_solve_time_milp = df_solve_time[lambda x: x.schedule_type == 'milp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab5590-bfe5-4f02-a378-48ab5b0a5379",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_latex = df_solve_time_milp[['time_limit', 'execution_time']].drop_duplicates().sort_values(by='time_limit')\n",
    "df_latex['time_limit'] = df_latex['time_limit'].astype(int)\n",
    "df_latex.columns = ['Time limit', 'Execution time']\n",
    "\n",
    "print(df_latex.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48707386-04a8-4fa7-b988-b6e6b8641a34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Rescheduling policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187e9f5-6a95-482a-98df-45b39756c46f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = \"../out/villalvernia/4_rescheduling_policy\"\n",
    "df_rescheduling_policy = load_data(basedir)\n",
    "df_rescheduling_policy_milp = df_rescheduling_policy[lambda x: x.schedule_type == 'milp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528de1c9-6af0-4474-87d5-40f0a64671b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_rescheduling_policy_milp.drop_duplicates('rescheduling_frequency').sort_values(by='rescheduling_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b1b156-1d47-4a75-9e55-83fc33854f80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = df_rescheduling_policy_milp.sort_values(by='rescheduling_frequency').drop_duplicates('rescheduling_frequency').rescheduling_frequency.astype(int)\n",
    "X = range(len(labels))\n",
    "Y = df_rescheduling_policy_milp.sort_values(by='rescheduling_frequency').drop_duplicates('rescheduling_frequency').execution_time\n",
    "\n",
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*0.65, dpi=100)\n",
    "plt.bar(X, Y, linewidth=.8, edgecolor='black', color=box_color, width=0.7)\n",
    "plt.xticks(ticks=X, labels=labels)\n",
    "plt.xlabel(\"Rescheduling frequency\")\n",
    "plt.ylabel(\"Execution\\ntime (s)\")\n",
    "\n",
    "plt.savefig(\"../out/figures/4_rescheduling_policy_execution_time.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199261df-9faf-4167-916a-3426f5a0d284",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = df_rescheduling_policy_milp.groupby('rescheduling_frequency').solve_time.sum().index \n",
    "X = range(len(labels))\n",
    "Y = df_rescheduling_policy_milp.groupby('rescheduling_frequency').solve_time.sum()\n",
    "\n",
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*0.65, dpi=100)\n",
    "plt.bar(X, Y, linewidth=.8, edgecolor='black', color=box_color, width=0.7)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel(\"Solving time\\n[sum] (s)\")\n",
    "plt.xticks([])\n",
    "\n",
    "plt.savefig(\"../out/figures/4_rescheduling_policy_solving_time_sum.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ba66e-8f31-450e-bdc7-88ca88e763bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Charging/depletion ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1b0cb-a91e-4400-918c-0f70df38b1ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = \"../out/villalvernia/5_charging_rate\"\n",
    "df_charging_rate = load_data(basedir).drop_duplicates(['schedule_type', 'r_charge']).sort_values('schedule_type', ascending=True).sort_values('r_charge', ascending=True)\n",
    "df_charging_rate['r_ratio'] = (df_charging_rate.r_charge / df_charging_rate.r_deplete).round(4)\n",
    "df_charging_rate_milp = df_charging_rate[lambda x: x.schedule_type == 'milp']\n",
    "df_charging_rate_naive = df_charging_rate[lambda x: x.schedule_type == 'naive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23107c-9e25-4f7f-9039-ab5bb1a032f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*1, dpi=100)\n",
    "df_plot = pd.concat([df_charging_rate_naive, df_charging_rate_milp])\n",
    "sns.barplot(data=df_plot, x='r_ratio', y='execution_time', hue='schedule_type', edgecolor='black', linewidth=0.75, hue_order=['naive', 'milp'])\n",
    "\n",
    "# add gains\n",
    "for i, r_ratio in enumerate(df_plot.r_ratio.unique()):\n",
    "    milp_time = df_charging_rate_milp[lambda x: x.r_ratio == r_ratio].iloc[0].execution_time\n",
    "    naive_time = df_charging_rate_naive[lambda x: x.r_ratio == r_ratio].iloc[0].execution_time\n",
    "    max_time = max(milp_time, naive_time)\n",
    "    rel_perc = (milp_time / naive_time * 100)\n",
    "    diff = 100 - rel_perc\n",
    "\n",
    "    if diff > 0:\n",
    "        color = 'green'\n",
    "        txt = r\"$\\downarrow$\" + f\"{-diff:.1f}%\"\n",
    "    else:\n",
    "        color = 'red'\n",
    "        txt = r\"$\\uparrow$\" + f\"+{-diff:.1f}%\"\n",
    "    plt.text(i, max_time + 50, txt, ha='center', va='bottom', backgroundcolor='white', color=color, fontsize=9, bbox=dict(boxstyle='square,pad=0.1', fc='white', ec='none'))\n",
    "\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.ylim([ymin, ymax+500])\n",
    "plt.legend(fontsize=8)\n",
    "# plt.xticks(ticks=df_plot.x_val.unique(), labels=df_plot.r_ratio.unique())\n",
    "plt.xlabel(r\"Ratio charging rate and depletion rate\")\n",
    "plt.ylabel(\"Execution time (s)\")\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.savefig(\"../out/figures/5_charging_rate.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8771afa-02fe-4930-80e8-167067f1ce48",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Charging cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b472485-c37f-45de-8c08-aab567f674f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = \"../out/villalvernia/6_charging_cycle\"\n",
    "df_charge_cycle = load_data(basedir).drop_duplicates(['schedule_type', 'B_min'])\n",
    "df_charge_cycle_milp = df_charge_cycle[lambda x: x.schedule_type == 'milp']\n",
    "df_charge_cycle_naive = df_charge_cycle[lambda x: x.schedule_type == 'naive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6919b-dbb9-4644-912c-2c1f61c285d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=np.array((4.5,2))*1, dpi=100)\n",
    "sns.barplot(data=df_charge_cycle, x='B_min', y='execution_time', hue='schedule_type', edgecolor='black', linewidth=0.75, hue_order=['naive', 'milp'])\n",
    "\n",
    "\n",
    "# add gains\n",
    "for i, B_min in enumerate(sorted(df_charge_cycle.B_min.unique())):\n",
    "    milp_time = df_charge_cycle_milp[lambda x: x.B_min == B_min].iloc[0].execution_time\n",
    "    naive_time = df_charge_cycle_naive[lambda x: x.B_min == B_min].iloc[0].execution_time\n",
    "    max_time = max(milp_time, naive_time)\n",
    "    rel_perc = (milp_time / naive_time * 100)\n",
    "    diff = 100 - rel_perc\n",
    "\n",
    "    if diff > 0:\n",
    "        color = 'green'\n",
    "        txt = r\"$\\downarrow$\" + f\"{-diff:.1f}%\"\n",
    "    else:\n",
    "        color = 'red'\n",
    "        txt = r\"$\\uparrow$\" + f\"+{-diff:.1f}%\"\n",
    "    plt.text(i, max_time + 50, txt, ha='center', va='bottom', backgroundcolor='white', color=color, fontsize=9, bbox=dict(boxstyle='square,pad=0.1', fc='white', ec='none'))\n",
    "    \n",
    "ymin, ymax = plt.ylim()\n",
    "plt.ylim([ymin, ymax+500])\n",
    "plt.legend(fontsize=8, loc='lower right')\n",
    "plt.xlabel(\"$B^{min}$\")\n",
    "plt.ylabel(\"Execution time (s)\")\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.savefig(\"../out/figures/6_charging_cycle.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
